{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.rcParams['image.interpolation'] = 'nearest'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T14:22:34.052817Z",
     "start_time": "2024-04-30T14:22:33.679782Z"
    }
   },
   "id": "35fac2e398941c90",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "from dataclasses import dataclass, field\n",
    "from typing import overload\n",
    "\n",
    "\n",
    "@dataclass(slots=True)\n",
    "class ImageData:\n",
    "    directory_path: Path = field(default_factory=Path)\n",
    "    \n",
    "    image_paths: list[Path] = field(init=False)\n",
    "    \n",
    "    def __post_init__(self) -> None:\n",
    "        with ZipFile(self.directory_path, 'r') as zip_file:\n",
    "            name = zip_file.namelist()[0]\n",
    "            zip_file.extractall(Path('./data/') / self.directory_path.parent)\n",
    "        \n",
    "        self.image_paths = list(\n",
    "            self.directory_path.parent.glob(f'{name}/[!.]*')\n",
    "        )\n",
    "    \n",
    "    @overload\n",
    "    def __getitem__(self, idx: int) -> np.ndarray:\n",
    "        return cv2.imread(str(self.image_paths[idx]), cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    def __getitem__(self, idx: str) -> np.ndarray:\n",
    "        return cv2.imread(self.directory_path.parent / idx, cv2.IMREAD_GRAYSCALE)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T14:22:34.392411Z",
     "start_time": "2024-04-30T14:22:34.386645Z"
    }
   },
   "id": "23c0556cf647f8d0",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "aloes = ImageData(Path('aloes.zip'))\n",
    "example = ImageData(Path('example.zip'))\n",
    "pairs = ImageData(Path('pairs.zip'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T14:22:35.173338Z",
     "start_time": "2024-04-30T14:22:35.062804Z"
    }
   },
   "id": "74b0539451f1389b",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "\n",
    "def calibrate_camera(data: ImageData) -> None:\n",
    "    # termination criteria\n",
    "    criteria: Tuple[int, int, float] = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "    calibration_flags: int = cv2.fisheye.CALIB_RECOMPUTE_EXTRINSIC + cv2.fisheye.CALIB_FIX_SKEW\n",
    "\n",
    "    # inner size of chessboard\n",
    "    width: int = 9\n",
    "    height: int = 6\n",
    "\n",
    "    # 0.025 meters\n",
    "    square_size: float = 0.025\n",
    "    \n",
    "    # prepare object points, like (0, 0, 0), (1, 0, 0), (2, 0, 0), ..., (8, 6, 0)\n",
    "    objp = np.zeros(( height * width, 1, 3), np.float64)\n",
    "    objp [:, 0, :2] = np.mgrid[0: width, 0: height ].T.reshape(-1, 2)\n",
    "    objp = objp * square_size # Create real world coords. Use your metric.\n",
    "    # Arrays to store object points and image points from all the images .\n",
    "    objpoints = [] # 3d point in real world space\n",
    "    imgpoints = [] # 2d points in image plane .\n",
    "    img_width = 640\n",
    "    img_height = 480\n",
    "    image_size = (img_width, img_height)\n",
    "    path = \"\"\n",
    "    image_dir = path + \"pairs/\"\n",
    "    number_of_images = 50\n",
    "    for i in range (1, number_of_images):\n",
    "        # read image\n",
    "        img = cv2.imread (image_dir + \" left_%02d.png \" % i)\n",
    "        gray = cv2.cvtColor (img , cv2. COLOR_BGR2GRAY)\n",
    "        # Find the chess board corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (width, height), cv2.CALIB_CB_ADAPTIVE_THRESH + cv2.CALIB_CB_FAST_CHECK + cv2.CALIB_CB_NORMALIZE_IMAGE)\n",
    "        Y, X, channels = img.shape\n",
    "        # skip images where the corners of the chessboard are too close to the edges of the image\n",
    "        if ret:\n",
    "            minRx = corners[: ,: ,0].min()\n",
    "            maxRx = corners[: ,: ,0].max()\n",
    "            minRy = corners[: ,: ,1].min()\n",
    "            maxRy = corners[: ,: ,1].max()\n",
    "            border_threshold_x = X /12\n",
    "            border_threshold_y = Y /12\n",
    "            x_thresh_bad = False\n",
    "            if ( minRx < border_threshold_x ):\n",
    "                x_thresh_bad = True\n",
    "            y_thresh_bad = False\n",
    "            if ( minRy < border_threshold_y ):\n",
    "                y_thresh_bad = True\n",
    "            if ( y_thresh_bad == True ) or ( x_thresh_bad == True ):\n",
    "                continue\n",
    "            # If found , add object points , image points ( after refining them )\n",
    "            if ret == True :\n",
    "                objpoints . append ( objp )\n",
    "                # improving the location of points (sub - pixel )\n",
    "                corners2 = cv2. cornerSubPix (gray , corners , (3, 3) , (-1, -1) , criteria )\n",
    "                imgpoints . append ( corners2 )\n",
    "                # Draw and display the corners\n",
    "                # Show the image to see if pattern is found ! imshow function .\n",
    "                cv2 . drawChessboardCorners (img , (width , height ), corners2 , ret )\n",
    "                cv2 . imshow (\" Corners \", img )\n",
    "                cv2 . waitKey (5)\n",
    "            else:\n",
    "                print (\" Chessboard couldn â€™t detected . Image pair : \", i)\n",
    "                continue"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c95e5c8fee472839"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "69ae956d3fc10a65"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "788b4690461df54a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "33a8845fe6cb327f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a1c993a443ecfc03"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "32c840841473f314"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "zaw",
   "language": "python",
   "display_name": "ZAW"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
