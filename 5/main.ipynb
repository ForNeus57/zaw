{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.rcParams['image.interpolation'] = 'nearest'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T16:06:50.012283Z",
     "start_time": "2024-04-30T16:06:49.612183Z"
    }
   },
   "id": "35fac2e398941c90",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "from dataclasses import dataclass, field\n",
    "from typing import overload\n",
    "\n",
    "\n",
    "@dataclass(slots=True)\n",
    "class ImageData:\n",
    "    directory_path: Path = field(default_factory=Path)\n",
    "    \n",
    "    image_paths: list[Path] = field(init=False)\n",
    "    \n",
    "    def __post_init__(self) -> None:\n",
    "        with ZipFile(self.directory_path, 'r') as zip_file:\n",
    "            name = zip_file.namelist()[0]\n",
    "            zip_file.extractall(Path('./data/') / self.directory_path.parent)\n",
    "        \n",
    "        self.image_paths = list(\n",
    "            self.directory_path.parent.glob(f'{name}/[!.]*')\n",
    "        )\n",
    "    \n",
    "    @overload\n",
    "    def __getitem__(self, idx: int) -> np.ndarray:\n",
    "        return cv2.imread(str(self.image_paths[idx]), cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    def __getitem__(self, idx: str) -> np.ndarray:\n",
    "        return cv2.imread(self.directory_path.parent / idx, cv2.IMREAD_GRAYSCALE)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T16:06:50.445992Z",
     "start_time": "2024-04-30T16:06:50.437582Z"
    }
   },
   "id": "23c0556cf647f8d0",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "aloes = ImageData(Path('aloes.zip'))\n",
    "example = ImageData(Path('example.zip'))\n",
    "pairs = ImageData(Path('pairs.zip'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T16:06:50.990024Z",
     "start_time": "2024-04-30T16:06:50.889285Z"
    }
   },
   "id": "74b0539451f1389b",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "\n",
    "# termination criteria\n",
    "criteria: Tuple[int, int, float] = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "calibration_flags: int = cv2.fisheye.CALIB_RECOMPUTE_EXTRINSIC + cv2.fisheye.CALIB_FIX_SKEW\n",
    "\n",
    "# inner size of chessboard\n",
    "width: int = 9\n",
    "height: int = 6\n",
    "\n",
    "# 0.025 meters\n",
    "square_size: float = 0.025\n",
    "\n",
    "# prepare object points, like (0, 0, 0), (1, 0, 0), (2, 0, 0), ..., (8, 6, 0)\n",
    "objp = np.zeros((height * width, 1, 3), np.float64)\n",
    "objp[:, 0, :2] = np.mgrid[0: width, 0: height].T.reshape(-1, 2)\n",
    "\n",
    "# Create real world coords. Use your metric.\n",
    "objp = objp * square_size\n",
    "\n",
    "# Arrays to store object points and image points from all the images .\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane .\n",
    "img_width = 640\n",
    "img_height = 480\n",
    "image_size = (img_width, img_height)\n",
    "\n",
    "path = \"./data/\"\n",
    "image_dir = path + \"pairs/\"\n",
    "\n",
    "number_of_images = 50\n",
    "for i in range (1, number_of_images):\n",
    "    # read image\n",
    "    img = cv2.imread(image_dir + \"left_%02d.png\" % i)\n",
    "    gray = cv2.cvtColor(img, cv2. COLOR_BGR2GRAY)\n",
    "    # Find the chess board corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (width, height), cv2.CALIB_CB_ADAPTIVE_THRESH + cv2.CALIB_CB_FAST_CHECK + cv2.CALIB_CB_NORMALIZE_IMAGE)\n",
    "    Y, X, channels = img.shape\n",
    "    # skip images where the corners of the chessboard are too close to the edges of the image\n",
    "    if ret:\n",
    "        minRx = corners[:, :, 0].min()\n",
    "        maxRx = corners[:, :, 0].max()\n",
    "        minRy = corners[:, :, 1].min()\n",
    "        maxRy = corners[:, :, 1].max()\n",
    "        \n",
    "        border_threshold_x = X / 12\n",
    "        border_threshold_y = Y / 12\n",
    "        \n",
    "        x_thresh_bad = minRx < border_threshold_x\n",
    "        y_thresh_bad = minRy < border_threshold_y\n",
    "        \n",
    "        if y_thresh_bad or x_thresh_bad:\n",
    "            continue\n",
    "        \n",
    "        # If found, add object points, image points (after refining them)\n",
    "        if ret:\n",
    "            objpoints.append(objp)\n",
    "            \n",
    "            # improving the location of points (sub - pixel)\n",
    "            corners2 = cv2.cornerSubPix(gray, corners, (3, 3), (-1, -1), criteria)\n",
    "            imgpoints.append(corners2)\n",
    "            \n",
    "            # Draw and display the corners\n",
    "            # Show the image to see if pattern is found !imshow function.\n",
    "            cv2.drawChessboardCorners(img, (width, height), corners2, ret)\n",
    "            cv2.imshow(\"Corners\", img)\n",
    "            cv2.waitKey(5)\n",
    "        else:\n",
    "            print(\"Chessboard couldn't detected. Image pair: \", i)\n",
    "            continue"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T16:06:53.125856Z",
     "start_time": "2024-04-30T16:06:51.422620Z"
    }
   },
   "id": "c95e5c8fee472839",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "N_OK = len(objpoints)\n",
    "K = np.zeros((3, 3))\n",
    "D = np.zeros((4, 1))\n",
    "rvecs = [np.zeros((1, 1, 3), dtype=np.float64) for i in range(N_OK)]\n",
    "tvecs = [np.zeros((1, 1, 3), dtype=np.float64) for i in range(N_OK)]\n",
    "ret, K, D, _, _ = cv2.fisheye.calibrate(\n",
    "    objpoints,\n",
    "    imgpoints,\n",
    "    image_size,\n",
    "    K,\n",
    "    D,\n",
    "    rvecs,\n",
    "    tvecs,\n",
    "    calibration_flags,\n",
    "    (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 1e-6),\n",
    ")\n",
    "\n",
    "# Let â€™s rectify our results\n",
    "map1, map2 = cv2.fisheye.initUndistortRectifyMap(K, D, np.eye(3), K, image_size, cv2.CV_16SC2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T16:06:54.361725Z",
     "start_time": "2024-04-30T16:06:54.058124Z"
    }
   },
   "id": "69ae956d3fc10a65",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "788b4690461df54a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "33a8845fe6cb327f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a1c993a443ecfc03"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "32c840841473f314"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "zaw",
   "language": "python",
   "display_name": "ZAW"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
